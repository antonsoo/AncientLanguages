"""create core tables

Revision ID: 94f9767a55ea
Revises: 8144e6c26432
Create Date: 2025-09-09 18:06:29.976848

"""

from typing import Sequence, Union

import sqlalchemy as sa
from sqlalchemy import text
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "94f9767a55ea"
down_revision: Union[str, Sequence[str], None] = "8144e6c26432"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def _has_vector_extension(bind) -> bool:
    """Check if pgvector extension is installed."""
    try:
        res = bind.execute(text("SELECT 1 FROM pg_extension WHERE extname = 'vector' LIMIT 1"))
        return bool(res.scalar())
    except Exception:
        return False


def _get_vector_column(dim: int):
    """Return vector column type if extension is available, otherwise BYTEA."""
    bind = op.get_bind()
    if _has_vector_extension(bind):
        from pgvector.sqlalchemy import Vector

        return Vector(dim)
    else:
        # Fallback to BYTEA when vector extension is not available
        # Vector embeddings won't work but the table can still be created
        return sa.LargeBinary


def upgrade() -> None:
    """Upgrade schema."""
    vector_col = _get_vector_column(1536)

    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "language",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("code", sa.String(length=8), nullable=False, unique=True),
        sa.Column("name", sa.String(length=64), nullable=False),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("language", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_language_code"), ["code"], unique=True)

    op.create_table(
        "source_doc",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("slug", sa.String(length=64), nullable=False),
        sa.Column("title", sa.String(length=256), nullable=False),
        sa.Column("license", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("meta", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("slug"),
    )
    op.create_table(
        "grammar_topic",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("source_id", sa.Integer(), nullable=False),
        sa.Column("anchor", sa.String(length=64), nullable=False),
        sa.Column("title", sa.String(length=256), nullable=False),
        sa.Column("body", sa.Text(), nullable=False),
        sa.Column("body_fold", sa.Text(), nullable=False),
        sa.Column("emb", vector_col, nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.ForeignKeyConstraint(
            ["source_id"],
            ["source_doc.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "lexeme",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("language_id", sa.Integer(), nullable=False),
        sa.Column("lemma", sa.String(length=150), nullable=False),
        sa.Column("lemma_fold", sa.String(length=150), nullable=False),
        sa.Column("pos", sa.String(length=32), nullable=True),
        sa.Column("data", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.ForeignKeyConstraint(
            ["language_id"],
            ["language.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("language_id", "lemma", name="uq_lex_lang_lemma"),
    )
    with op.batch_alter_table("lexeme", schema=None) as batch_op:
        batch_op.create_index("ix_lexeme_lang_lemma", ["language_id", "lemma"], unique=False)
        batch_op.create_index(batch_op.f("ix_lexeme_language_id"), ["language_id"], unique=False)
        batch_op.create_index(batch_op.f("ix_lexeme_lemma"), ["lemma"], unique=False)
        batch_op.create_index(batch_op.f("ix_lexeme_lemma_fold"), ["lemma_fold"], unique=False)

    op.create_table(
        "text_work",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("language_id", sa.Integer(), nullable=False),
        sa.Column("source_id", sa.Integer(), nullable=False),
        sa.Column("author", sa.String(length=128), nullable=False),
        sa.Column("title", sa.String(length=256), nullable=False),
        sa.Column("ref_scheme", sa.String(length=64), nullable=False),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.ForeignKeyConstraint(
            ["language_id"],
            ["language.id"],
        ),
        sa.ForeignKeyConstraint(
            ["source_id"],
            ["source_doc.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("text_work", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_text_work_language_id"), ["language_id"], unique=False)

    op.create_table(
        "text_segment",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("work_id", sa.Integer(), nullable=False),
        sa.Column("ref", sa.String(length=64), nullable=False),
        sa.Column("text_raw", sa.Text(), nullable=False),
        sa.Column("text_nfc", sa.Text(), nullable=False),
        sa.Column("text_fold", sa.Text(), nullable=False),
        sa.Column("emb", vector_col, nullable=True),
        sa.Column("meta", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.ForeignKeyConstraint(
            ["work_id"],
            ["text_work.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("work_id", "ref", name="uq_segment_ref"),
    )
    with op.batch_alter_table("text_segment", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_text_segment_work_id"), ["work_id"], unique=False)

    op.create_table(
        "token",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("segment_id", sa.Integer(), nullable=False),
        sa.Column("idx", sa.Integer(), nullable=False),
        sa.Column("surface", sa.String(length=150), nullable=False),
        sa.Column("surface_nfc", sa.String(length=150), nullable=False),
        sa.Column("surface_fold", sa.String(length=150), nullable=False),
        sa.Column("lemma", sa.String(length=150), nullable=True),
        sa.Column("lemma_fold", sa.String(length=150), nullable=True),
        sa.Column("msd", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), server_default=sa.text("now()"), nullable=False),
        sa.ForeignKeyConstraint(
            ["segment_id"],
            ["text_segment.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("token", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_token_lemma"), ["lemma"], unique=False)
        batch_op.create_index(batch_op.f("ix_token_lemma_fold"), ["lemma_fold"], unique=False)
        batch_op.create_index("ix_token_loc", ["segment_id", "idx"], unique=False)
        batch_op.create_index(batch_op.f("ix_token_segment_id"), ["segment_id"], unique=False)
        batch_op.create_index(batch_op.f("ix_token_surface_fold"), ["surface_fold"], unique=False)
        batch_op.create_index(batch_op.f("ix_token_surface_nfc"), ["surface_nfc"], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("token", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_token_surface_nfc"))
        batch_op.drop_index(batch_op.f("ix_token_surface_fold"))
        batch_op.drop_index(batch_op.f("ix_token_segment_id"))
        batch_op.drop_index("ix_token_loc")
        batch_op.drop_index(batch_op.f("ix_token_lemma_fold"))
        batch_op.drop_index(batch_op.f("ix_token_lemma"))

    op.drop_table("token")
    with op.batch_alter_table("text_segment", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_text_segment_work_id"))

    op.drop_table("text_segment")
    with op.batch_alter_table("text_work", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_text_work_language_id"))

    op.drop_table("text_work")
    with op.batch_alter_table("lexeme", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_lexeme_lemma_fold"))
        batch_op.drop_index(batch_op.f("ix_lexeme_lemma"))
        batch_op.drop_index(batch_op.f("ix_lexeme_language_id"))
        batch_op.drop_index("ix_lexeme_lang_lemma")

    op.drop_table("lexeme")
    op.drop_table("grammar_topic")
    op.drop_table("source_doc")
    with op.batch_alter_table("language", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_language_code"))

    op.drop_table("language")
    # ### end Alembic commands ###
